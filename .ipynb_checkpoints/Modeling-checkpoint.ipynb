{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e48e563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model & metric imports\n",
    "# Specific imports\n",
    "# These are new! Notice we're using the 'from' approach to import only what we need.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Model Imports\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "\n",
    "# Create a custom color map.\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Statistics imports\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import csv\n",
    "import import_ipynb\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99f35e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/891/data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5051fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple feature with feature transformation\n",
    "\n",
    "X = df[['Income','GenHlth','MentHlth','PhysHlth','DiffWalk']]\n",
    "y  = df[\"Diabetes_binary\"]  #Linear Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0668ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple feature with feature transformation\n",
    "\n",
    "X = df[[\"Income\",\"PhysHlth\",\"DiffWalk\"]]\n",
    "y  = df[\"Diabetes_binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "478b774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_acc(df, feature_cols, response, f_num,track_df):\n",
    "    \"\"\"accepts a list of features and stores acc values in dataframe\"\"\"\n",
    "    # Create feature matrix (X).\n",
    "    X = df[feature_cols]\n",
    "   \n",
    "    # Create response vector (y).\n",
    "    y = df[response]       #independenct variable\n",
    "        \n",
    "    \n",
    "    \n",
    "    #initialize the StandardScaler object -- \n",
    "    s = StandardScaler()\n",
    "     \n",
    "    #use fit transform function to standardize   X \n",
    "    X_scaled  = s.fit_transform(X)\n",
    "    \n",
    "    #Step 1: Split X and y into training and testing sets (using random_state for reproducibility).\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled,y,random_state=46)\n",
    "\n",
    "   # Instantiate a KNN Classifier KNeighborsClassifier with n_neighbors=1\n",
    "    #knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    logreg = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "    \n",
    "    #Set model on the training data\n",
    "    # Fit the model\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    #Test Accuracy\n",
    "    y_pred_test  = logreg.predict(X_test)\n",
    "    \n",
    "    # compute the accuracy\n",
    "    acc_test =accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    #Train accuracy\n",
    "    y_pred_train  = logreg.predict(X_train)\n",
    "    \n",
    "    # compute the accuracy\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Diff Test and Train accuracy\n",
    "    result =  acc_train - acc_test \n",
    "    \n",
    "    \n",
    "   # listToStr = ','.join([str(elem) for elem in feature_cols])\n",
    "   # \n",
    "   # new_row = pd.DataFrame({'feature_set' :  \"feature_set_\" + str(f_num) , 'acc_test':acc_test,'acc_train':acc_train,\n",
    "   ##                          'acc_diff':abs(result),'score':acc_test, 'cols_' : listToStr},index=[1,2,3 ])\n",
    "   # track_df = pd.concat([track_df,new_row] )\n",
    "    \n",
    "    return result   #track_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd23290",
   "metadata": {},
   "source": [
    "#### Test out several feature combination.  Select the best accuracy score but not too perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6064d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 =['Income','GenHlth','MentHlth','PhysHlth','DiffWalk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d9d85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col2 =['Income', 'PhysHlth','DiffWalk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dbc140d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col3 = ['HighBP', 'HighChol', 'CholCheck', 'BMI',\n",
    "       'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits',\n",
    "       'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost',\n",
    "       'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age',\n",
    "       'Education', 'Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a07f4c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI',\n",
       "       'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits',\n",
       "       'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost',\n",
       "       'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age',\n",
       "       'Education', 'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03fa9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_data = [col1,col2,col3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0ae60",
   "metadata": {},
   "source": [
    "#### Step 3: run functions using csv file and write accuracy results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b30f510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe to track results\n",
    "track_logresults = pd.DataFrame(columns = [ 'feature_set','acc_train','acc_test','acc_diff','score', 'cols_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84a3d827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002028802691054321\n",
      "0.002028802691054321\n",
      "0.002028802691054321\n"
     ]
    }
   ],
   "source": [
    "for row in features_data :\n",
    "    #print (row)  \n",
    "    for i, col in enumerate(row):      #loop every item in that row. Row = row, i = index, col is the actual text\n",
    "        if i == 0:\n",
    "            index_ = col\n",
    "        if i == 1:\n",
    "            feature_set = (col.strip().split(\",\"))\n",
    "            print(train_test_acc(df, feature_set, 'Diabetes_binary',index_,track_logresults))\n",
    "            #track_logresults = train_test_acc(df, feature_set, 'Diabetes_binary',index_,track_logresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "80662906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To shorten my notebook I added my features columns to a file\n",
    "#pd.set_option('max_colwidth',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "56c5d142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_set</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_diff</th>\n",
       "      <th>score</th>\n",
       "      <th>cols_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature_set, acc_train, acc_test, acc_diff, score, cols_]\n",
       "Index: []"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#sort columns to view best accuracy result\n",
    "track_logresults.drop_duplicates().sort_values(by= ['score','acc_diff'] ,ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a54891",
   "metadata": {},
   "source": [
    "I am getting 100% accuracy on my column combinations.  I guess its just the dataset sample I am using so I will opt to go with feature columns set col1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4772ec9a",
   "metadata": {},
   "source": [
    "### Prepare X, y Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d4395",
   "metadata": {},
   "source": [
    "\n",
    "Nominal Classification Problem: Predict diabetis for a customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f6cf0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "y = df['Diabetes_binary']\n",
    "X = df[col1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eeee3a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  GenHlth  MentHlth  PhysHlth  DiffWalk\n",
       "0       3        5        18        15         1\n",
       "1       1        3         0         0         0\n",
       "2       8        5        30        30         1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc0b0483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253680, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ee7e3",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d3a01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X) \n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "689fe66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4744874 ,  2.32912057,  1.99859213,  1.23399871,  2.22361507],\n",
       "       [-2.44013754,  0.45729435, -0.42962961, -0.48659241, -0.44971813]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled [:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e08d7",
   "metadata": {},
   "source": [
    "### Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd8093c",
   "metadata": {},
   "source": [
    "Logistic Regression using Test Train Split\n",
    "KNN using a cross-validation, GridSearch\n",
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68095ba8",
   "metadata": {},
   "source": [
    "#### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9844e1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=123)\n",
    "\n",
    "logreg  = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3352ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#predict values usign X test\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7cf92efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8573005361084831\n",
      "Test Accuracy: 0.8573005361084831\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# What is our accuracy on the test set?\n",
    "\n",
    "# Evaluate the performance using .score() method.\n",
    "\n",
    "acc_test =logreg.score(X_test, y_test)\n",
    "print(f'Test Accuracy: {acc_test}')\n",
    "#verify accuracy result\n",
    "print(f'Test Accuracy: {np.mean(y_test == logreg.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2fc449ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8582571218332807\n",
      "Train Accuracy: 0.8582571218332807\n"
     ]
    }
   ],
   "source": [
    "# What is our accuracy on the test set?\n",
    "\n",
    "# Evaluate the performance using .score() method.\n",
    "\n",
    "acc_train =logreg.score(X_train, y_train)\n",
    "print(f'Train Accuracy: {acc_train}')\n",
    "#verify accuracy result\n",
    "print(f'Train Accuracy: {np.mean(y_train == logreg.predict(X_train))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14341437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between test and train: 0.0009565857247976206\n"
     ]
    }
   ],
   "source": [
    "print(f'Difference between test and train: {abs(acc_train - acc_test) }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9b1ca",
   "metadata": {},
   "source": [
    "Difference between test and train is 0.0009565"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc7ab1",
   "metadata": {},
   "source": [
    "#### View confusion matrix detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85cfb593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53c31f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions variable will be used in RFC table below to view cm matrix results\n",
    " \n",
    "definitions = pd.Series([\"none\",\"Diabetes\" ], dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a4e3c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none', 1: 'Diabetes'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reversefactor = dict(zip(range(2),definitions))\n",
    "reversefactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8356e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Type      0    1\n",
      "Actual Type               \n",
      "0               53970  607\n",
      "1                8443  400\n"
     ]
    }
   ],
   "source": [
    "#Reverse factorize (converting y_pred from 0s,1s,2s,3s,4s to \n",
    "#Dissatfied, loyalist, High_Maintenance,Potential_Loyalist, and Satisified\n",
    "\n",
    "y_test_v = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred_v = np.vectorize(reversefactor.get)(y_pred)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Type'], colnames=['Predicted Type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "45b01bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.86\n",
      "Micro Recall: 0.86\n",
      "Micro F1-score: 0.86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix statisitics\n",
    "#for multi-class classificaiton we only need to calcuate the Micro average\n",
    "#In a multi-class classification setup with highly imbalanced classes, micro-averaging is preferable over macro-averaging.\n",
    "#reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#one-vs-rest-multiclass-roc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210e79a",
   "metadata": {},
   "source": [
    "It is calculated by considering the total TP, total FP and total FN of the model. It does not consider each class individually, It calculates the metrics globally.\n",
    "\n",
    "As you can see When we are calculating the metrics globally all the measures become equal. Also if you calculate accuracy you will see that,\n",
    "\n",
    "Precision = Recall = Micro F1 = Accuracy\n",
    "\n",
    "Interpretation: Precision is higher than the recall and both precisio and recall are lower than total accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a84b68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Precision: 0.80\n",
      "Weighted Recall: 0.86\n",
      "Weighted F1-score: 0.81\n"
     ]
    }
   ],
   "source": [
    "#Looks at all of the individual types and the total weight avearge\n",
    "\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df2558",
   "metadata": {},
   "source": [
    "Interpretation: The average performance of each on of the individual customer types have a 80% precision on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2eb351",
   "metadata": {},
   "source": [
    "Will test with 1-more model.  Searching for a model that will have a better accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1350ae",
   "metadata": {},
   "source": [
    "### SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "05fdd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e24f154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64c960cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try joblib, which is more efficient at handling large numpy arrays of data.\n",
    "from joblib import dump, load\n",
    "\n",
    "# Save the model as a pickle file\n",
    "dump(logreg, 'data/prepared/logreg_mfrancis870.pkl')\n",
    "\n",
    "# Load fthe model from the file\n",
    "logreg_from_joblib = load('data/prepared/logreg_mfrancis870.pkl')\n",
    "\n",
    "# Use the model to make predictions\n",
    "y_pred_from_joblib = logreg_from_joblib.predict(X_test)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d691789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR RMSE: 0.37775582575456973\n",
      "LR Pickle RMSE: 0.37775582575456973\n"
     ]
    }
   ],
   "source": [
    "# Testing RMSE\n",
    "# Compute Test RMSE for both models\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_logreg_joblib = np.sqrt(mean_squared_error(y_test, y_pred_from_joblib))\n",
    "\n",
    "print(f'LR RMSE: {rmse_lr}')\n",
    "print(f'LR Pickle RMSE: {rmse_logreg_joblib}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7888c",
   "metadata": {},
   "source": [
    "### Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1d03a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the StandardScaler object -- \n",
    "s = StandardScaler()\n",
    "     \n",
    "#use fit transform function to standardize   X \n",
    "X_scaled = s.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "84e58e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#y = df['types']\n",
    "#X = cleaned_data[feature_set]\n",
    "#Step 1: Split X and y into training and testing sets (using random_state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)\n",
    "\n",
    "#Step 2: Instantiate\n",
    "rfc = RandomForestClassifier(random_state=1234)\n",
    "# fit the model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3c770f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.854399243140965"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model using the .score method\n",
    "acc_rfc_test = rfc.score(X_test, y_test)\n",
    "acc_rfc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bc0952e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8702354672553348"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model using the .score method\n",
    "acc_rfc_train = rfc.score(X_train, y_train)\n",
    "acc_rfc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e4ffe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is better using the Random Forest Model by 0.011978345422054115 percent\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy is better using the Random Forest Model by {acc_rfc_train - acc_train  } percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ec2c5",
   "metadata": {},
   "source": [
    "I will use the Random Forest model to make my predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc7633c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the StandardScaler object -- \n",
    "s = StandardScaler()\n",
    "     \n",
    "#use fit transform function to standardize   X \n",
    "X_scaled = s.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b05285",
   "metadata": {},
   "source": [
    "# NEED TO RESEARCH HOW TO PACKAGE MY MODEL AND USE IT IN A REAL APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad35f277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training MSE: 0.1297645327446652\n",
      " Testing MSE:  0.145600756859035\n",
      "\n",
      " Training RMSE: 0.36022844521867675\n",
      " Testing RMSE:  0.38157667232030185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Training MSe\n",
    "mse_train = mean_squared_error(y_train, rfc.predict(X_train))\n",
    "\n",
    "# Testing MSE\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f' Training MSE: {mse_train}')\n",
    "print(f' Testing MSE:  {mse_test}')\n",
    "\n",
    "# Training and TestingRMSE\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "print()\n",
    "print(f' Training RMSE: {rmse_train}')\n",
    "print(f' Testing RMSE:  {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e3dd5358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC RMSE: 0.38157667232030185\n",
      "RFC Pickle RMSE: 0.38157667232030185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Using pickle\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(rfc, open(\"data/prepared/rfc_mfrancis870.pkl\", 'wb'))\n",
    "\n",
    "# Restore the model\n",
    "rfc_from_pickle = pickle.load(open('data/prepared/rfc_mfrancis870.pkl', 'rb'))\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred_from_pickle = rfc_from_pickle.predict(X_test)\n",
    "\n",
    "# Compute Test RMSE for both models\n",
    "rmse_rfc = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_rfc_pickle = np.sqrt(mean_squared_error(y_test, y_pred_from_pickle))\n",
    "\n",
    "print(f'RFC RMSE: {rmse_rfc}')\n",
    "print(f'RFC Pickle RMSE: {rmse_rfc_pickle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "49112903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_pred[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ccdf8235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92783</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19519</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239829</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179386</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Income  GenHlth  MentHlth  PhysHlth  DiffWalk\n",
       "92783        8        1         0         0         0\n",
       "19519        5        3         0         0         0\n",
       "239829       8        3         5         0         0\n",
       "179386       7        3        10         5         1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ab3d449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC RMSE: 0.38157667232030185\n",
      "RFC Pickle RMSE: 0.38157667232030185\n"
     ]
    }
   ],
   "source": [
    "# Try joblib, which is more efficient at handling large numpy arrays of data.\n",
    "from joblib import dump, load\n",
    "\n",
    "# Save the model as a pickle file\n",
    "dump(rfc, 'data/prepared/rfc_mfrancis870.pkl')\n",
    "\n",
    "# Load fthe model from the file\n",
    "rfc_from_joblib = load('data/prepared/rfc_mfrancis870.pkl')\n",
    "\n",
    "# Use the model to make predictions\n",
    "y_pred_from_joblib = rfc_from_joblib.predict(X_test)\n",
    "\n",
    "# Testing RMSE\n",
    "# Compute Test RMSE for both models\n",
    "rmse_rfc = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_rfc_joblib = np.sqrt(mean_squared_error(y_test, y_pred_from_joblib))\n",
    "\n",
    "print(f'RFC RMSE: {rmse_rfc}')\n",
    "print(f'RFC Pickle RMSE: {rmse_rfc_joblib}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "965e6953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/prepared/RandomForestClassifier.joblib']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save my model to score new data\n",
    "# to score new data\n",
    "\n",
    "joblib.dump(rfc, 'data/prepared/RandomForestClassifier.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72d5b4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "169d0416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.to_csv('data/prepared/X_test_ScoreNewData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a26c6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('data/prepared/y_test_ScoreNewData.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d4240",
   "metadata": {},
   "source": [
    "I did open the value and edit the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "914f72b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37775582575456973\n"
     ]
    }
   ],
   "source": [
    "print(rmse_logreg_joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ab65a0b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38157667232030185\n"
     ]
    }
   ],
   "source": [
    "print(rmse_rfc_joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cf037a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0038208465657321167"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_logreg_joblib - rmse_rfc_joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f4d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2db98ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RandomForest model outperformed the Logistic  model by 0.0038208465657321167\n"
     ]
    }
   ],
   "source": [
    "print(f'The RandomForest model outperformed the Logistic  model by { rmse_rfc_joblib - rmse_logreg_joblib  }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962552ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
